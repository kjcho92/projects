{"cells":[{"cell_type":"markdown","source":["# Train and Deploy a Fastai v1 Image Classification Model on Azure Machine Learning \n","\n","In this notebook we will do the following: \n","\n","1) Train a model locally with Azure Compute Instance (CI).\n","2) Log metrics to Azure Machine Learning. \n","3) Learn how to register a model in your Azure Machine Learning Workspace.\n","4) Deploy your model as a web service in an Azure Container Instance (ACI) and call the webservice. "],"metadata":{}},{"cell_type":"code","source":["print(\"I can start editing with no connected compute\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["I can start editing with no connected compute\n"]}],"execution_count":1,"metadata":{"collapsed":true,"outputExpanded":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#This is to ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook.\n","%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"outputs":[],"execution_count":2,"metadata":{}},{"cell_type":"markdown","source":["We import all the necessary packages. We are going to work with the fastai V1 library (Pytorch 1.0). The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models."],"metadata":{}},{"cell_type":"code","source":["!pip install fastai\n","from fastai.vision import *\n","from fastai.metrics import error_rate"],"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: fastai in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (1.0.61)\n","Requirement already satisfied: beautifulsoup4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (4.8.0)\n","Requirement already satisfied: packaging in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (19.2)\n","Requirement already satisfied: pandas in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (0.23.4)\n","Requirement already satisfied: torchvision in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (0.6.0a0+82fd1c8)\n","Requirement already satisfied: numexpr in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (2.7.0)\n","Requirement already satisfied: torch>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.5.0)\n","Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (3.2.1)\n","Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (2.23.0)\n","Requirement already satisfied: pyyaml in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (5.1.2)\n","Requirement already satisfied: nvidia-ml-py3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (7.352.0)\n","Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (2.2.4)\n","Requirement already satisfied: bottleneck in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.2.1)\n","Requirement already satisfied: fastprogress>=0.2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (0.2.3)\n","Requirement already satisfied: numpy>=1.15 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.16.2)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (0.7)\n","Requirement already satisfied: Pillow in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (6.2.0)\n","Requirement already satisfied: scipy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.4.1)\n","Requirement already satisfied: soupsieve>=1.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from beautifulsoup4->fastai) (1.9.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->fastai) (2.4.2)\n","Requirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->fastai) (1.12.0)\n","Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas->fastai) (2.8.0)\n","Requirement already satisfied: pytz>=2011k in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas->fastai) (2019.3)\n","Requirement already satisfied: future in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from torch>=1.0.0->fastai) (0.18.2)\n","Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai) (1.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (1.24.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (2020.4.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (2.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (3.0.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.45.0)\n","Requirement already satisfied: thinc==7.4.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n","Requirement already satisfied: setuptools in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (41.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.6.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.23)\n","Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.6.0)\n","Requirement already satisfied: more-itertools in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.2.0)\n"]}],"execution_count":3,"metadata":{}},{"cell_type":"markdown","source":["# Connect to Workspace \n","\n","Create a workspace object from the existing workspace. Workspace.from_config() reads the file config.json and loads the details into an object named ws."],"metadata":{}},{"cell_type":"code","source":["import azureml \n","from azureml.core import Workspace\n","\n","ws = Workspace.from_config()\n","print(ws.get_details())"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'id': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/PipelinesUsabilityStudy/providers/Microsoft.MachineLearningServices/workspaces/shwinneworkshop', 'name': 'shwinneworkshop', 'location': 'eastus2', 'type': 'Microsoft.MachineLearningServices/workspaces', 'tags': {}, 'sku': 'Enterprise', 'workspaceid': '2c99da6f-e7fc-4070-b1f7-204807455abf', 'description': '', 'friendlyName': '', 'creationTime': '2020-01-13T20:47:53.0433365+00:00', 'containerRegistry': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/PipelinesUsabilityStudy/providers/Microsoft.ContainerRegistry/registries/shwinneworks933cbd9b', 'keyVault': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourcegroups/pipelinesusabilitystudy/providers/microsoft.keyvault/vaults/shwinneworksho8870415227', 'applicationInsights': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourcegroups/pipelinesusabilitystudy/providers/microsoft.insights/components/shwinneworksho2947248937', 'identityPrincipalId': '96324b21-c7ac-40df-91a6-d978ae017864', 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47', 'identityType': 'SystemAssigned', 'storageAccount': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourcegroups/pipelinesusabilitystudy/providers/microsoft.storage/storageaccounts/shwinneworksho1645067620', 'hbiWorkspace': False, 'discoveryUrl': 'https://eastus2.experiments.azureml.net/discovery'}\n"]}],"execution_count":4,"metadata":{}},{"cell_type":"markdown","source":["# Dataset \n","\n","We are going to use the Food 101 dataset (https://www.kaggle.com/kmader/food41#1028787.jpg ) which features 101 food categories, with 101'000 images. For each class, 250 manually reviewed test images are provided as well as 750 training images. For the purpose of this notebook, we will be classifying amongst 5 different food categories (applie pie, waffles, padthai, bread pudding and ramen). We will be using only 200 images per food category. We will use a training set of 160 images and a validation set of 60 images for each class of food. \n","\n","Please download the images from Kaggle into separate folders and create 5 datasets for each of the categories of food by following the instructions in the prepare-dataset.md file."],"metadata":{}},{"cell_type":"code","source":["#Get and download food images from the 'File Datasets' from your workspace.\n","#Create directories for your classes and choose an appropriate folder name for your labeled images.\n","\n","from azureml.core import Dataset\n","\n","apple_pie_dataset = Dataset.get_by_name(ws, name='apple-pie')\n","apple_pie_dataset.download(target_path='./apple-pie', overwrite=False)\n","\n","waffles_dataset = Dataset.get_by_name(ws, name='waffles')\n","waffles_dataset.download(target_path='./data/waffles', overwrite=False)\n","\n","padthai_dataset = Dataset.get_by_name(ws, name='pad-thai')\n","padthai_dataset.download(target_path='./data/padthai', overwrite=False)\n","\n","breadpudding_dataset = Dataset.get_by_name(ws, name='bread-pudding')\n","breadpudding_dataset.download(target_path='./breadpudding', overwrite=False)\n","\n","ramen_dataset = Dataset.get_by_name(ws, name='ramen')\n","ramen_dataset.download(target_path='./data/ramen', overwrite=False)"],"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/abe-vm/code/Users/fastai-on-aml/apple-pie/3068872.jpg\" already exists. Set overwrite=True to overwrite it.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-963091c2c968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mapple_pie_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'apple-pie'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mapple_pie_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./apple-pie'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwaffles_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'waffles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_info'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/file_dataset.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, target_path, overwrite)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_encode_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# encode p to avoid UnicodeEncodeError from os.path.exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                     raise RuntimeError('File \"{}\" already exists. Set overwrite=True to overwrite it.'\n\u001b[0;32m--> 128\u001b[0;31m                                        .format(p))\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalFileOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/abe-vm/code/Users/fastai-on-aml/apple-pie/3068872.jpg\" already exists. Set overwrite=True to overwrite it."]}],"execution_count":5,"metadata":{}},{"cell_type":"code","source":["import pathlib\n","from pathlib import Path\n","\n","#list the directories to the images \n","path = Path('.')\n","path.ls()"],"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":["[PosixPath('.config'),\n"," PosixPath('.ipynb_checkpoints'),\n"," PosixPath('apple-pie'),\n"," PosixPath('breadpudding'),\n"," PosixPath('breadpudding.jpg'),\n"," PosixPath('data'),\n"," PosixPath('dataset.md'),\n"," PosixPath('dataset2.PNG'),\n"," PosixPath('dataset3.PNG'),\n"," PosixPath('datasets.png'),\n"," PosixPath('download'),\n"," PosixPath('export.pkl'),\n"," PosixPath('food-image-classification.ipynb'),\n"," PosixPath('IMDB'),\n"," PosixPath('models'),\n"," PosixPath('myenv.yml'),\n"," PosixPath('other.ipynb'),\n"," PosixPath('outputs'),\n"," PosixPath('padthai'),\n"," PosixPath('ramen'),\n"," PosixPath('score.py'),\n"," PosixPath('train-local-and-deploy-fastai-model.ipynb'),\n"," PosixPath('train-remote-and-deploy-fastai-model.ipynb'),\n"," PosixPath('train.py'),\n"," PosixPath('train_remote.py'),\n"," PosixPath('waffles'),\n"," PosixPath('workspaceblobstore'),\n"," PosixPath('__pycache__')]"]},"metadata":{}}],"execution_count":30,"metadata":{}},{"cell_type":"code","source":["#These are the classes for your food categories\n","\n","classes = ['apple-pie','breadpudding','padthai', 'ramen', 'waffles']\n"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#Remove any images that cannot be opened. \n","\n","for c in classes:\n","    print(c)\n","    verify_images(path/c, delete=True, max_size=2200)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["# View Data\n","\n","ImageDataBunch returns a data bunch object which is needed for modeling in fast AI. This contains the images and labels for the training, validation and/or test datasets. \n","\n","We want to ensure that all images are the same shape and size for better GPU performance. We will use size = 224 to ensure that all the images are of 224x224 square size.\n","\n","If the data is not normalized, we can have difficulty training a model. We want the red, green and blue channels of the images to have a mean of 0 and standard deviation of 1. The get_transforms function ensures that the image sizes are 224 x 224 by doing a combination of techniques such as center cropping and resizing. "],"metadata":{}},{"cell_type":"code","source":["np.random.seed(42)\n","data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n","        ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#let's take a look at our delicious food! Yummm....\n","\n","data.show_batch(rows=5, figsize=(7,6))"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["data.classes, data.c, len(data.train_ds), len(data.valid_ds)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["# Training \n","\n","For more information on Convolutional Neural Networks please see http://cs231n.github.io/convolutional-networks/ .We will train a CNN to classify food images for 5 types of food. "],"metadata":{}},{"cell_type":"code","source":["#create your model called 'learn'\n","\n","learn = cnn_learner(data, models.resnet34, metrics=accuracy)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["learn.fit_one_cycle(2)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#Export the model. This step is important if you want to perform inferencing. \n","\n","learn.path = Path(\".\") \n","learn.export()\n","path = learn.path\n","path"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#scoring using fastai \n","img = open_image('data/apple-pie/3068872.jpg')\n","img\n","pred_class,pred_idx,outputs = learn.predict(img)\n","pred_class"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["interp = ClassificationInterpretation.from_learner(learn)\n","interp.plot_confusion_matrix()"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["# Create Experiment \n","\n","Create an experiment to track the runs in your workspace. A workspace can have multiple experiments."],"metadata":{}},{"cell_type":"code","source":["from azureml.core import Experiment, Run\n","\n","#create new AML experiment \n","experiment = Experiment(ws, 'fastai-food-classification')"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["%%writefile train.py\n","\n","from fastai.vision import (ImageDataBunch, get_transforms, cnn_learner, models, imagenet_stats, accuracy)\n","from pathlib import Path \n","from azureml.core.run import Run \n","import numpy as np\n","\n","# get the Azure ML run object\n","run = Run.get_context()\n","\n","# get images\n","path = Path('data')\n","np.random.seed(2)\n","data = ImageDataBunch.from_folder(path,\n","                                       train=\".\",\n","                                       valid_pct=0.2,\n","                                       ds_tfms=get_transforms(),\n","                                       size=224).normalize(imagenet_stats)\n","\n","# build estimator based on ResNet 34\n","learn = cnn_learner(data, models.resnet34, metrics=accuracy)\n","learn.fit_one_cycle(2)\n","\n","# do test time augmentation and get accuracy\n","acc = accuracy(*learn.TTA())\n","\n","\n","# log the accuracy to run\n","run.log('Accuracy', np.float(acc))\n","print(\"Accuracy: \", np.float(acc))\n","\n","# Save the model to the root. Note: this is not registering model\n","#learn.path = Path(\".\")\n","#learn.export()\n","#path = learn.path\n","#path"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["# System-managed environment \n","\n","Now, instead of managing the setup of the environment yourself, you can ask the system to build a new conda environment for you. The environment is built once, and will be reused in subsequent executions as long as the conda dependencies remain unchanged."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.environment import CondaDependencies\n","from azureml.core import Environment\n","from azureml.core import ScriptRunConfig\n","\n","\n","#If your total snapshot size exceeds the limit of 300.0 MB, uncomment the below line. Please see http://aka.ms/aml-largefiles on how to work with large files.\n","azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 5000000000\n","\n","myenv = Environment(name=\"myenv\")\n","conda_dep = CondaDependencies()\n","conda_dep.add_pip_package(\"fastai\")\n","conda_dep.add_pip_package(\"ipykernel\")\n","myenv.python.conda_dependencies=conda_dep\n","\n","myenv.python.user_managed_dependencies = False\n","\n","#To submit a run, create a run configuration that combines the script file and environment, and pass it to Experiment.submit. \n","#In this example, the script is submitted to local computer, but you can specify other compute targets such as remote clusters as well.\n","\n","runconfig = ScriptRunConfig(source_directory=\".\", script=\"train.py\")\n","runconfig.run_config.target = \"local\"\n","runconfig.run_config.environment = myenv\n","run = experiment.submit(config=runconfig)\n","\n","run.wait_for_completion(show_output=True)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["from azureml.widgets import RunDetails \n","RunDetails(run).show()"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["#Register Model\n","\n","Register a file or folder as a model by calling [Model.register()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-). In addition to the content of the model file itself, your registered model will also store model metadata, model description, tags, and framework information that will be useful when managing and deploying models in your workspace. Using tags, for instance, you can categorize your models and apply filters when listing models in your workspace. Also, marking this model with the scikit-learn framework will simplify deploying it as a web service, as we'll see later.\n"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.model import Model\n","\n","#Register the model\n","model = Model.register(model_path = \"export.pkl\", # this points to a local file\n","                       model_name = \"food_classification_model2\", # this is the name the model is registered as\n","                       tags = {'food': \"Yummmm :)\"},\n","                       description = \"Model predicting types of food\",\n","                       workspace = ws)\n","\n","print(model.name, model.description, model.version)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["# Prepare to deploy\n","\n","\n","To deploy the model, you need the following items:\n","\n","1) An entry script, this script accepts requests, scores the requests by using the model, and returns the results.\n","\n","2) Dependencies, like helper scripts or Python/Conda packages required to run the entry script or model.\n","\n","3) The deployment configuration for the compute target that hosts the deployed model. This configuration describes things like memory and CPU requirements needed to run the model.\n","\n","Define your entry script and dependencies\n","\n","We will first write the entry script as shown below. Note a few points in the entry script.\n","\n","The script contains two functions that load and run the model:\n","\n","init(): Typically, this function loads the model into a global object. This function is run only once, when the Docker container for your web service is started. Ensure to make your global declarations inside of the init() function. \n","\n","run(request): This function uses the model to predict a value based on the input data. Inputs and outputs of the run typically use JSON for serialization and deserialization. You can also work with raw binary data. You can transform the data before sending it to the model or before returning it to the client."],"metadata":{}},{"cell_type":"markdown","source":["The fastai predict function returns the object predicted (with the class in this instance), the underlying data (here the corresponding index) and the raw probabilities. You can also do inference on a larger set of data by adding a test set. This is done by passing an ItemList to load_learner. Please see https://docs.fast.ai/tutorial.inference.html for more information. "],"metadata":{}},{"cell_type":"code","source":["%%writefile score.py\n","\n","import os\n","import json\n","from azureml.core.model import Model\n","from azureml.core import Workspace\n","import fastai \n","from fastai.vision import *\n","from fastai.metrics import accuracy \n","from fastai.metrics import error_rate\n","import urllib.request\n","\n","\n","def download_jpg(url):\n","    file_path = \"./breadpudding.jpg\"\n","    local_filename, header = urllib.request.urlretrieve(url, file_path)    \n","    return local_filename\n","\n","def init():   \n","    global food_classification_model\n","    # The AZUREML_MODEL_DIR environment variable indicates a directory containing the model file you registered.  \n","    #this init works \n","    model_path=os.getenv('AZUREML_MODEL_DIR')     \n","    filename=\"export.pkl\"\n","    classes = ['apple-pie','breadpudding','padthai', 'ramen', 'waffles']\n","    food_classification_model = load_learner(path=model_path, file=filename)   \n","    classes = food_classification_model.data.classes\n","    print(classes)\n","\n","\n","def run(request):   \n","    candidate_url = json.loads(request)[\"url\"]   \n","    file_path = download_jpg(candidate_url)\n","    img = open_image(file_path)\n","    prediction = food_classification_model.predict(img)\n","    index = 0\n","    pred = str(prediction[index])\n","    print(pred)\n","    return pred\n","\n","\n","# if __name__ == \"__main__\":\n","#     init()  \n","#     request = { \"url\": \"https://i.imgur.com/TqlREOJ.jpg\"}\n","#     run(request)\n","#     print(\"main\")"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["Define dependencies\n","The following YAML is the Conda dependencies file we will use for inference. If you want to use automatic schema generation, your entry script must import the inference-schema packages."],"metadata":{}},{"cell_type":"code","source":["%%writefile myenv.yml\n","\n","name: project_environment\n","dependencies:\n","- python=3.6.9\n","\n","- pip:\n","  - fastai==1.0.60\n","  - torch\n","  - torchvision  \n","  - azureml-defaults\n","  - azureml-core\n","  - matplotlib==3.1.2\n","- numpy==1.16.2\n","- Pillow==6.2.0\n","- pandas==0.23.4\n","\n"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["from azureml.core import Environment\n","\n","# Instantiate environment\n","myenv = Environment.from_conda_specification(name = \"myenv\",\n","                                             file_path = \"myenv.yml\")"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["Define your inference configuration. The inference configuration describes how to configure the model to make predictions. This configuration isn't part of your entry script. It references your entry script and is used to locate all the resources required by the deployment. It's used later, when you deploy the model.\n"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.model import InferenceConfig\n","\n","inference_config = InferenceConfig(entry_script='score.py', environment=myenv)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["# Deploy Model\n","\n","Before deploying your model, you must define the deployment configuration. The deployment configuration is specific to the compute target that will host the web service. The deployment configuration isn't part of your entry script. It's used to define the characteristics of the compute target that will host the model and entry script.\n","\n","You can customize the deploy configuration (i.e. the number of cores and amount of memory made available for the deployment) using the [AciWebservice.deploy_configuration()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none--dns-name-label-none--).\n","        \n","**Note**: This step can take several minutes."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice\n","\n","aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n","                                               memory_gb=1, \n","                                               tags = {'task': \"image-classification\"}, \n","                                               description='A model to predict types of food')"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["Deployment uses the inference configuration deployment configuration to deploy the models. The deployment process is similar regardless of the compute target"],"metadata":{}},{"cell_type":"code","source":["service = Model.deploy(ws, name='food-classification-aci', models=[model], inference_config= inference_config, deployment_config=aciconfig)\n","service.wait_for_deployment(True)\n","print(service.state)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["After your model is deployed, make a call to the web service using [service.run()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#run-input-)."],"metadata":{}},{"cell_type":"code","source":["import json\n","  \n","request = json.dumps({\"url\": \"https://i.imgur.com/TqlREOJ.jpg\"})\n","prediction = service.run(request)\n","print(prediction)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["When you are finished testing your service, clean up the deployment with [service.delete()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#delete--)."],"metadata":{}},{"cell_type":"code","source":["service.delete()"],"outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"kernel_info":{"name":"python3-azureml"},"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":4}